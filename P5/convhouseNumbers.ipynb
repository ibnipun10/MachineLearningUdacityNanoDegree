{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CapStone Project\n",
    "\n",
    "#### This project will try to create a convolution Neural network, train it with Street view house numbers and calculate the accuracy of predicting of house numbers \n",
    "\n",
    "Data set \n",
    "http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "##### For visualization of the house numbers images you can have a look at the site provided above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as scp\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data \n",
    "testData = scp.loadmat('../../data/svhn/test_32x32.mat')\n",
    "trainData = scp.loadmat('../../data/svhn/train_32x32.mat')\n",
    "\n",
    "logs_path = '/home/ubuntu/tensorFlowLogs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDataX = testData['X'].astype('float32') / 128.0 - 1         \n",
    "testDataY = testData['y']\n",
    "\n",
    "trainDataX = trainData['X'].astype('float32') / 128.0 - 1\n",
    "trainDataY = trainData['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "train Data image shape :  (32, 32, 3, 73257)\n",
      "train data output shape :  (73257, 1)\n",
      "test data image shape :  (32, 32, 3, 26032)\n",
      "test data output shape :  (26032, 1)\n"
     ]
    }
   ],
   "source": [
    "print type(trainDataX)\n",
    "print type(trainDataY)\n",
    "\n",
    "print 'train Data image shape : ', trainDataX.shape\n",
    "print 'train data output shape : ', trainDataY.shape\n",
    "print 'test data image shape : ', testDataX.shape\n",
    "print 'test data output shape : ', testDataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try tansposing the array\n",
    "def transposeArray(data):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in xrange(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    \n",
    "    xtrain = np.asarray(xtrain)\n",
    "    return xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train data image shape :  (73257, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "trainDataX = transposeArray(trainDataX)\n",
    "testDataX = transposeArray(testDataX)\n",
    "\n",
    "\n",
    "print 'New train data image shape : ', trainDataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OnehotEndoding(Y):\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "        \n",
    "    return np.asarray(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data output shape :  (73257, 10)\n",
      "test data output shape :  (26032, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert y to one hot encoding\n",
    "trainDataY = OnehotEndoding(trainDataY)\n",
    "testDataY = OnehotEndoding(testDataY)\n",
    "print 'train data output shape : ', trainDataY.shape\n",
    "print 'test data output shape : ', testDataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neural network parameters\n",
    "height = 32\n",
    "width = 32\n",
    "channel = 3\n",
    "tags = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "num_hidden = 128\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stddev = 0.1\n",
    "tf_X = tf.placeholder(\"float\", shape=[None, height, width, channel], name = \"X-Input\")\n",
    "tf_Y = tf.placeholder(\"float\", shape=[None, tags], name = \"LabeledData\")\n",
    "\n",
    "convW1 = tf.Variable(tf.random_normal([patch, patch, channel, depth], stddev=stddev), name=\"ConvW1\")\n",
    "bias1 = tf.Variable(tf.random_normal([depth], stddev=stddev), name=\"Bias1\")\n",
    "\n",
    "convW2 = tf.Variable(tf.random_normal([patch, patch, depth, depth], stddev=stddev), name=\"ConvW2\")\n",
    "bias2 = tf.Variable(tf.random_normal([depth], stddev=stddev), name = \"Bias2\")\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([height // 4 * width // 4 * depth, num_hidden], stddev=stddev), name=\"w3\")\n",
    "bias3 = tf.Variable(tf.random_normal([num_hidden]), name=\"bias3\")\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([num_hidden, tags], stddev=stddev), name=\"w4\")\n",
    "bias4 = tf.Variable(tf.random_normal([tags], stddev=stddev), name=\"bias4\")  \n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the model I have tried to build\n",
    "Input Image : 32x32x3\n",
    "first Convolution Hidden layer : 5x5x3x16\n",
    "Padding : Same, Stride : [1,2,2,1]\n",
    "Output of first Convolution Hidden layer : 16x16x16\n",
    "\n",
    "Second Convolution Hidden layer : 5x5x16x16\n",
    "Padding : Same, Stride : [1,2,2,1]\n",
    "Output of Second Convolution Hidden layer : 8x8x16\n",
    "\n",
    "third Hidden Layer fully connected : 8x8x16\n",
    "Output of third Hidden layer : 64\n",
    "\n",
    "Fourth Hidden Layer : 64 x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "def model(X):\n",
    "    \n",
    "    #first layer : Convolution\n",
    "    conv = tf.nn.conv2d(X, convW1, [1,1,1,1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + bias1)\n",
    "    \n",
    "    #second layer : pooling\n",
    "    hidden2 = tf.nn.max_pool(hidden1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    #third layer : convolution\n",
    "    conv2 = tf.nn.conv2d(hidden2, convW2, [1,1,1,1], padding='SAME')\n",
    "    hidden3 = tf.nn.relu(conv2 + bias2)\n",
    "    \n",
    "    #fourth layer : pooling\n",
    "    hidden4 = tf.nn.max_pool(hidden3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    #reshape it to a single Dimensional\n",
    "    shape = hidden4.get_shape()\n",
    "    \n",
    "    #5th layer : fully connected\n",
    "    newInput = tf.reshape(hidden4, [-1, shape[1].value * shape[2].value * shape[3].value])\n",
    "    hidden5 = tf.nn.relu(tf.matmul(newInput, w3) + bias3)\n",
    "    \n",
    "    dp5 = tf.nn.dropout(hidden5, keep_prob)\n",
    "    \n",
    "    return tf.matmul(dp5, w4) + bias4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Model'):\n",
    "    pred = model(tf_X)\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, tf_Y))\n",
    "\n",
    "\n",
    "# Optimizer.\n",
    "with tf.name_scope('AdamOptimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1),tf.argmax(tf_Y,1)), \"float\"))\n",
    "    \n",
    "# Create a summary to monitor cost tensor\n",
    "tf.scalar_summary(\"loss\", loss)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.scalar_summary(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Accuracy(X, Y, message, sess):    \n",
    "    print message, sess.run(accuracy, feed_dict= {tf_X: X, tf_Y: Y, keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "cost at each step : 0 is : 2.74266\n",
      "cost at each step : 500 is : 2.41081\n",
      "cost at each step : 1000 is : 2.50079\n",
      "cost at each step : 1500 is : 2.11996\n",
      "cost at each step : 2000 is : 2.11162\n",
      "cost at each step : 2500 is : 2.97314\n",
      "cost at each step : 3000 is : 2.46293\n",
      "cost at each step : 3500 is : 2.46613\n",
      "cost at each step : 4000 is : 2.33491\n",
      "cost at each step : 4500 is : 2.48325\n",
      "cost at each step : 5000 is : 1.98877\n",
      "cost at each step : 5500 is : 2.81711\n",
      "cost at each step : 6000 is : 2.27586\n",
      "cost at each step : 6500 is : 1.98614\n",
      "cost at each step : 7000 is : 2.10391\n",
      "cost at each step : 7500 is : 2.39799\n",
      "cost at each step : 8000 is : 2.22084\n",
      "cost at each step : 8500 is : 2.3874\n",
      "cost at each step : 9000 is : 2.59603\n",
      "cost at each step : 9500 is : 2.26875\n",
      "cost at each step : 10000 is : 2.16372\n",
      "cost at each step : 10500 is : 2.3386\n",
      "cost at each step : 11000 is : 2.03488\n",
      "cost at each step : 11500 is : 2.53223\n",
      "cost at each step : 12000 is : 2.51826\n",
      "cost at each step : 12500 is : 1.94748\n",
      "cost at each step : 13000 is : 2.02629\n",
      "cost at each step : 13500 is : 2.5035\n",
      "cost at each step : 14000 is : 2.13899\n",
      "cost at each step : 14500 is : 2.30404\n",
      "cost at each step : 15000 is : nan\n",
      "cost at each step : 15500 is : nan\n",
      "cost at each step : 16000 is : nan\n",
      "cost at each step : 16500 is : nan\n",
      "cost at each step : 17000 is : nan\n",
      "cost at each step : 17500 is : nan\n",
      "cost at each step : 18000 is : nan\n",
      "cost at each step : 18500 is : nan\n",
      "cost at each step : 19000 is : nan\n",
      "cost at each step : 19500 is : nan\n",
      "cost at each step : 20000 is : nan\n",
      "cost at each step : 20500 is : nan\n",
      "cost at each step : 21000 is : nan\n",
      "cost at each step : 21500 is : nan\n",
      "cost at each step : 22000 is : nan\n",
      "cost at each step : 22500 is : nan\n",
      "cost at each step : 23000 is : nan\n",
      "cost at each step : 23500 is : nan\n",
      "cost at each step : 24000 is : nan\n",
      "cost at each step : 24500 is : nan\n",
      "cost at each step : 25000 is : nan\n",
      "cost at each step : 25500 is : nan\n",
      "cost at each step : 26000 is : nan\n",
      "cost at each step : 26500 is : nan\n",
      "cost at each step : 27000 is : nan\n",
      "cost at each step : 27500 is : nan\n",
      "cost at each step : 28000 is : nan\n",
      "cost at each step : 28500 is : nan\n",
      "cost at each step : 29000 is : nan\n",
      "cost at each step : 29500 is : nan\n",
      "cost at each step : 30000 is : nan\n",
      "cost at each step : 30500 is : nan\n",
      "cost at each step : 31000 is : nan\n",
      "cost at each step : 31500 is : nan\n",
      "cost at each step : 32000 is : nan\n",
      "cost at each step : 32500 is : nan\n",
      "cost at each step : 33000 is : nan\n",
      "cost at each step : 33500 is : nan\n",
      "cost at each step : 34000 is : nan\n",
      "cost at each step : 34500 is : nan\n",
      "cost at each step : 35000 is : nan\n",
      "cost at each step : 35500 is : nan\n",
      "cost at each step : 36000 is : nan\n",
      "cost at each step : 36500 is : nan\n",
      "cost at each step : 37000 is : nan\n",
      "cost at each step : 37500 is : nan\n",
      "cost at each step : 38000 is : nan\n",
      "cost at each step : 38500 is : nan\n",
      "cost at each step : 39000 is : nan\n",
      "cost at each step : 39500 is : nan\n",
      "cost at each step : 40000 is : nan\n",
      "cost at each step : 40500 is : nan\n",
      "cost at each step : 41000 is : nan\n",
      "cost at each step : 41500 is : nan\n",
      "cost at each step : 42000 is : nan\n",
      "cost at each step : 42500 is : nan\n",
      "cost at each step : 43000 is : nan\n",
      "cost at each step : 43500 is : nan\n",
      "cost at each step : 44000 is : nan\n",
      "cost at each step : 44500 is : nan\n",
      "cost at each step : 45000 is : nan\n",
      "cost at each step : 45500 is : nan\n",
      "cost at each step : 46000 is : nan\n",
      "cost at each step : 46500 is : nan\n",
      "cost at each step : 47000 is : nan\n",
      "cost at each step : 47500 is : nan\n",
      "cost at each step : 48000 is : nan\n",
      "cost at each step : 48500 is : nan\n",
      "cost at each step : 49000 is : nan\n",
      "cost at each step : 49500 is : nan\n",
      "accuracy of test data :  0.169407\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    epoch = 10000\n",
    "    batch_size = 20\n",
    "    print('Initialized')\n",
    "    \n",
    "    p = np.random.permutation(range(len(trainDataX)))\n",
    "    trX, trY = trainDataX[p], trainDataY[p]\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    for step in range(epoch):\n",
    "        start = end\n",
    "        end = start + batch_size\n",
    "        \n",
    "        if start >= len(trainDataX):\n",
    "            start = 0\n",
    "            end = start + batch_size\n",
    "            \n",
    "        if end >= len(trainDataX):\n",
    "            end = len(trainDataX) - 1\n",
    "            \n",
    "        #batch = np.random.choice(len(trainDataX) - 1, batch_size)\n",
    "        inX, outY = trX[start:end], trY[start:end]\n",
    "        _, summary = sess.run(optimizer, merged_summary_op, feed_dict= {tf_X: inX, tf_Y: outY, keep_prob:0.75})\n",
    "        summary_writer.add_summary(summary, step)\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print 'cost at each step :', step, 'is :', sess.run(loss, feed_dict={tf_X: inX, tf_Y: outY, keep_prob:1.0})\n",
    "    \n",
    "    #Accuracy(trX, trY, 'accuracy of training data : ', sess)\n",
    "    Accuracy(testDataX, testDataY, 'accuracy of test data : ', sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
